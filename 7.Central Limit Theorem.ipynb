{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2583755f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Bernouli Distribution\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7hcxVvxrANdBbgD5FLXpCQ.png\" width=\"300px\"><br>\n",
    "  <em>Bernoulli Distribution</em>\n",
    "</p>\n",
    "\n",
    "- BERNOULLI and BINOMIAL these two are DISCRETE distributions.\n",
    "- Bernoulli distribution has ‚ÄúBINARY OUTCOME‚Äù.\n",
    "- Ex- Coin Toss, yes, no, Success, failure, email spam, ham.\n",
    "- Rolling a dice and getting a 5, here coming 5 is a success, and if other numbers occur, it counts as a failure. Probability is for 5 is 1/5 and for ~5 is 5/6.\n",
    "- When we have a binary outcome-based random experiment it comes under the Bernoulli distribution.\n",
    "- In the machine learning domain, if we want to make an email spam classifier based on output new mail is either spam or ham. This is also a random experiment, if we have spam as success and denote as ‚Äò1‚Äô and have ham mail denoted as ‚Äò0‚Äô so here ‚Äò1‚Äô can be anything positive, or negative.\n",
    "\n",
    "Bernoulli Distribution is a probability distribution that models a binary outcome, where the result can be either success (represented by the value 1) or failure (represented by the value 0). The Bernoulli distribution is named after the Swiss Mathematician Jacob Bernoulli, who first introduced it in the late 1600s.\n",
    "\n",
    "The Bernoulli Distribution is characterized by a single parameter, the probability of success, denoted by P.\n",
    "\n",
    "Since it is DISCRETE distribution, it must have PMF (Probability Mass Function), CDF (Cumulative Distribution Function).\n",
    "\n",
    "### PMF (Probability Mass Function) of Bernoulli:-\n",
    "\n",
    "P(X = x)\n",
    "\n",
    "P(X = x) = p^x (1 - p)^{1 - x}\n",
    "\n",
    "The PMF can be expressed as:\n",
    "\n",
    "$$\n",
    "f(k; p) = p^k (1 - p)^{1-k} \\quad \\text{for } k \\in \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "Alternatively, it is often written as:\n",
    "\n",
    "$$\n",
    "P(X = k) =\n",
    "\\begin{cases}\n",
    "p & \\text{if } k = 1 \\\\\n",
    "1 - p & \\text{if } k = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- The probability of X being equal to small x is represented by p^x, while the probability of X being equal to 1 minus small x is represented by (1 ‚àí p)^{1 ‚àí x}.\n",
    "- Here p is the probability of success and since it is a binary outcome so 1 ‚àí p will be the probability of failure.\n",
    "- PMF of the Bernoulli graph has only 2 lines 0 and 1 on x axis.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6tjl5Io_6ouwu9o7uGFI7Q.png\" width=\"300px\"><br>\n",
    "  <em>Bernoulli PMF</em>\n",
    "</p>\n",
    "\n",
    "- This distribution we can see in MACHINE LEARNING algorithms like Logistic Regression, SVM, Decision Tree, and Na√Øve Bayes. Data inside this algorithm use Bernoulli.\n",
    "- It is most useful with BINOMIAL DISTRIBUTION.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644bd7b",
   "metadata": {},
   "source": [
    "## Binomial Distribution\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:600/format:webp/1*nFaNmjIZi13ZNvrt1FjHvw.png\" width=\"300px\"><br>\n",
    "</p>\n",
    "\n",
    "- Bernoulli is a special case of Binomial distribution.\n",
    "- Bernoulli's trial should be ‚ÄúINDEPENDENT‚Äù, which means the trial should be strictly independent.  \n",
    "  Ex- first-time head coming does not decide what comes next.  \n",
    "  Ex- giving a rating for the course by one student does not affect by rating given by another student.\n",
    "- In the Bernoulli distribution, we perform binary outcomes for only one time, like we find success or failure for once only.\n",
    "- The binomial distribution is just a general case of Bernoulli distribution as here we are performing Bernoulli distribution ‚ÄúN‚Äù times. If perform only one time then it is Bernoulli but if we do it for n number of times is binomial.\n",
    "- The binomial distribution is characterized by two parameters: the number of trials n and the probability of success p.\n",
    "- If N = 1 then ‚ÄòBinomial becomes Bernoulli‚Äô.\n",
    "- If we do the coin toss for 1 then it is Bernoulli and if toss the coin multiple times it becomes binomial.\n",
    "- Analyzing a single email to determine if it‚Äôs spam or not spam constitutes a Bernoulli trial. However, when inspecting a batch of emails, such as 100 or 1000, and discerning the ratio of spam to legitimate messages, it falls under a binomial distribution.\n",
    "\n",
    "### The kind of problem we can solve through BINOMIAL distribution:-\n",
    "\n",
    "Finding the probability of anyone watching a YouTube famous video and then liking it is 0.5, what is the probability that:\n",
    "\n",
    "- > yes, no / yes, no / yes, no ‚Äî 2¬≥ = 8 possibilities of entire sample space.\n",
    "- > (YYY, NNN, YYN, YNN, YNY, NYY, NNY, NYN)\n",
    "\n",
    "1. No one out of 3 people likes YouTube videos (1/8) possibility\n",
    "2. 1 out of 3 people like it (3/8) possibility\n",
    "3. 2 out of 3 people like it (3/8) possibility\n",
    "4. 3 out of 3 people like it (1/8) possibility\n",
    "\n",
    "With the help of ‚ÄúSAMPLE SPACE,‚Äù we solve this problem. But if we have huge data solving this through sample space will be difficult. So binomial distribution will help in solving this by using PDF.\n",
    "\n",
    "### The Probability Mass Function (PMF) is given by:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "* **$n$**: Number of independent trials.\n",
    "* **$x$**: Number of desired successes (the random variable).\n",
    "* **$p$**: Probability of success in a single trial.\n",
    "* **$1-p$**: Probability of failure in a single trial (often denoted as $q$).\n",
    "* **$\\binom{n}{x}$**: The binomial coefficient, calculated as  \n",
    "  $\\frac{n!}{x!(n-x)!}$.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: YouTube Video Likes\n",
    "\n",
    "**Scenario:** Finding the probability that exactly **2 out of 3** people like a YouTube video, assuming a $1/2$ (50%) chance for each person.\n",
    "\n",
    "**Parameters:**\n",
    "* $n = 3$ (total people)\n",
    "* $x = 2$ (desired result)\n",
    "* $p = 1/2$ (probability of liking)\n",
    "\n",
    "**Calculation:**\n",
    "\n",
    "$$\n",
    "P(X = 2) = \\binom{3}{2} \\left(\\frac{1}{2}\\right)^2 \\left(\\frac{1}{2}\\right)^{3-2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(X = 2) = \\frac{3!}{2!(3-2)!} \\times \\left(\\frac{1}{4}\\right) \\times \\left(\\frac{1}{2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(X = 2) = 3 \\times \\frac{1}{8} = \\frac{3}{8}\n",
    "$$\n",
    "\n",
    "**Result:**  \n",
    "The probability is **0.375** (or **37.5%**).\n",
    "\n",
    "---\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "* **Mean ($\\mu$):** $np$\n",
    "* **Variance ($\\sigma^2$):** $np(1-p)$\n",
    "* **Condition:** Trials must be independent, and the probability $p$ must remain constant.\n",
    "\n",
    "### Graph of PDF:-\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KqyjuQHIg7AnMejt6ZEu5w.png\" width=\"300px\"><br>\n",
    "  <em>Binomial Distribution with different probability success</em>\n",
    "</p>\n",
    "\n",
    "- PDF graph of Binomial Distribution is similar to Normal Distribution.\n",
    "- This is one PDF graph with different probabilities of success. If we increase the probability of success ex; p = 0.9 then the graph moves towards the right.\n",
    "- If the probability of success ex; p = 0.2 then the graph moves towards left. And if p = 0.6 somewhere around 0.5 in the middle, then the graph is very similar to normal distribution.\n",
    "\n",
    "### Criteria to consider Binomial Distribution:-\n",
    "\n",
    "1. There are more than one trials\n",
    "2. Only 2 exclusive outcomes are possible, a success and a failure\n",
    "3. P(success) is called ‚Äî ‚ÄòP‚Äô and probability of failure is called ‚Äî (1 ‚àí P), and it is fixed from trial to trial\n",
    "4. The trials are independent\n",
    "\n",
    "### Application in Data Science\n",
    "\n",
    "1. **Binary Classification Problem:**  \n",
    "   In classification, we have algorithms like Na√Øve Bayes, Binomial Na√Øve Bayes, Multinomial Na√Øve Bayes, and other variations of the algorithm, internally based on the process that column of the data showing which type of characteristics it is showing ‚Äî binomial distribution, multinomial distribution, or Gaussian distribution.  \n",
    "   Ex ‚Äî In a spam detection system, we may model the probability of an email being spam or not spam using a binomial distribution.\n",
    "\n",
    "2. **Hypothesis Testing:**  \n",
    "   Here we use binomial distribution to calculate the probability of observing a certain number of successes in a given number of trials, assuming a null hypothesis is true. This can be used to decide whether a certain hypothesis is supported by the data or not.\n",
    "\n",
    "3. **Logistic Regression:**  \n",
    "   In Logistic Regression, the logistic function can be viewed as a transformation of a linear combination of inputs, and the output of logistic regression can be thought of as a binomial distribution.\n",
    "\n",
    "4. **A/B Testing:**  \n",
    "   It is a common technique used to compare two different versions of a product, web page, or marketing campaign. In A/B testing, we randomly assign individuals to one of two groups and compare the outcome of interest between the groups.\n",
    "\n",
    "   Since the outcomes are often binary (eg; click-through rate or conversion rate), the binomial distribution can be used to model the distribution of outcomes and test for differences between the groups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a420967",
   "metadata": {},
   "source": [
    "## Sampling Distribution\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*kr0Rge3WaLRPYWCrFG4QiA.jpeg\" width=\"400px\"><br>\n",
    "</p>\n",
    "\n",
    "- To understand the Central Limit Theorem, grasping the concept of population and sample is essential. The population refers to the entire dataset available, like the complete data of a college. Conversely, a sample involves selecting data points based on various criteria, such as class, batch, subject, or age, from the entire population, to infer about the whole population.\n",
    "- For instance, imagine we want to determine the average salary across India. The entire salary data represents the population, while randomly selecting individuals to calculate their salary average forms the first sample. This process is repeated multiple times, generating 100 sets of 50 individuals each. Then, the averages of these 100 samples of 50 people are computed.\n",
    "- These 100 sample means collectively constitute the sampling distribution of the sample mean. Similarly, we can derive other measures of central tendency, such as standard deviation or variance, for these 100 sets of 50 individuals, resulting in the sampling distribution of the sample variance or standard deviation.\n",
    "\n",
    "A sampling distribution represents the statistical characteristics of sample statistics, such as the sample mean or proportion. It‚Äôs derived from computing these statistics across multiple independent samples of the same size from a population.\n",
    "\n",
    "To create a sampling distribution, we repeatedly draw samples of the same size from the population, without limit. For each sample, we calculate summary statistics like the mean, median, or variance. The collection of these summary statistics across all samples forms the sampling distribution of the respective statistic, whether it‚Äôs the mean, variance, or any other summary measure.\n",
    "\n",
    "#### Why Sampling Distribution is so important?\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*zAgxEsR4cvL-dUWxEN-vVA.png\" width=\"300px\"><br>\n",
    "  <em>Any distribution type to Normal distribution by sampling distribution</em>\n",
    "</p>\n",
    "\n",
    "- Because it allows us to estimate the variability of sample statistics, which is useful for making inferences about the population.\n",
    "- The sampling distribution is important in statistics and machine learning because it allows us to estimate the variability of sample statistics, which is useful for making inferences about the population.\n",
    "- By analyzing the properties of the sampling distribution, we can compute confidence intervals, perform hypothesis tests, and make predictions about the population based on the sample data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9cd68",
   "metadata": {},
   "source": [
    "## Intuition of Central Limit Theorem (CTL)\n",
    "\n",
    "The Central Limit Theorem (CLT) states that the distribution of the sample means of a large number of independent and identically distributed random variables will approach a normal distribution, regardless of the underlying distribution of the variables.\n",
    "\n",
    "**The conditions required for the CLT to hold are:**\n",
    "\n",
    "1. The sample size is large enough, typically greater than or equal to 30.\n",
    "2. The sample is drawn from a finite population or an infinite population with a finite variance.\n",
    "3. The random variables in the sample are independent and identically distributed.\n",
    "\n",
    "According to the Central Limit Theorem, when we plot the distribution of data that we collect after sampling distribution of any summary statistics (mean, median, mode, variance, St. Deviation), it will be a ‚ÄúNormal Distribution‚Äù.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*w7Ksp8cTHjTJYjgtZCU69g.jpeg\" width=\"300px\"><br>\n",
    "  <em>Uniform distribution ‚Äî Normal Distribution Hence proved</em>\n",
    "</p>\n",
    "\n",
    "**Also, it does not matter how the distribution of the population either Log Normal, Uniform, Pareto, Exponential, Binomial, or any other distribution or if it does not follow any prominent distribution still it will give Normal distribution on sample data if it is derived by sampling distribution.**\n",
    "\n",
    "## Assumptions of Making Samples\n",
    "\n",
    "**The Central Limit Theorem holds some assumptions that need to be fulfilled to get normally distributed data.**\n",
    "\n",
    "1. A minimum of 30 or more than that should be the sample size. In the above example, we take 100 sets of sample sizes.\n",
    "2. Distribution should be finite or its variance also should be finite, otherwise, it will not work.\n",
    "\n",
    "- > Ex:- A bag full of candy (red, green, blue). Distribution of candies should be finite, which means there are a limited number of different types of candies in the bag, like we have red, green, and blue. And if the variance is finite, it means the differences between the candies (or numbers) in the bag are not too extreme or wildly different from each other.\n",
    "\n",
    "3. The sample that we take should be identical and independent.\n",
    "\n",
    "- > Ex:- Identical means each sample of candy should be a true representative of the population or say full bag of candy that we are trying to study.  \n",
    "- > Independent means that the outcome of one sample does not affect the outcome of another sample. In our example, this means that if we pick out a red candy from the bag in one sample, it does not change the probability of picking a blue candy in the next sample.\n",
    "\n",
    "If the population mean is ‚Äúmu‚Äù and variance is ‚Äúsigma square‚Äù, then the normal distribution which we form its mean will be the same and the standard deviation will be sigma square by n ($\\sigma^2 / n$), where ‚Äôn‚Äô represents the sample size, which in our example is n = 100.\n",
    "\n",
    "So if we find ‚Äòsample mean‚Äô and ‚Äòstandard deviation‚Äô, then we can find ‚Äòpopulation mean and population standard deviation‚Äô.\n",
    "\n",
    "As we increase the sample size, it gives a more proper Normal Distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a8826",
   "metadata": {},
   "source": [
    "## CLT in code\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Applying Binomial Model with 1000 sample size and 10 trials \n",
    "\n",
    "n = 10  # number of trials\n",
    "p = 0.1  # probability of success\n",
    "size = 1000  # number of samples to generate\n",
    "\n",
    "binomial_dist = np.random.binomial(n, p, size)\n",
    "\n",
    "plt.hist(binomial_dist,density=True)\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*qPraIMCgPVWR0QWzCq0j5g.png\" width=\"300px\"><br>\n",
    "  <em>Binomial Distribution</em>\n",
    "</p>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters\n",
    "num_samples = 1000\n",
    "sample_size = 30\n",
    "distribution_range = (0, 1)\n",
    "\n",
    "# Generate samples from a uniform distribution\n",
    "samples = np.random.uniform(distribution_range[0], distribution_range[1], (num_samples, sample_size))\n",
    "\n",
    "# Calculate the sample means\n",
    "sample_means = np.mean(samples, axis=1)\n",
    "\n",
    "# Plot the histogram of the sample means\n",
    "plt.hist(sample_means, bins=30, density=True, edgecolor='black')\n",
    "plt.title('Histogram of Sample Means')\n",
    "plt.xlabel('Sample Mean')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*2_7DhgkGFb9eMCMKReMu8g.png\" width=\"300px\"><br>\n",
    "  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2de128",
   "metadata": {},
   "source": [
    "## Case study : Restaurant Wait Times\n",
    "\n",
    "**Scenario:**\n",
    "A popular restaurant has highly skewed wait times (right-skewed distribution):\n",
    "- Most customers wait 5-15 minutes\n",
    "- Some wait 30-60 minutes during rush hours\n",
    "- Population mean (Œº) = 20 minutes\n",
    "- Population std deviation (œÉ) = 15 minutes\n",
    "- Original distribution: RIGHT-SKEWED (not normal)\n",
    "\n",
    "**Question:** What's the probability that the average wait time for 36 randomly selected customers is less than 18 minutes?\n",
    "\n",
    "\n",
    "**Step 1: Check if CLT applies**\n",
    "- Sample size n = 36 ‚â• 30 ‚úì\n",
    "- Even though population is skewed, CLT says sample means will be normal\n",
    "\n",
    "\n",
    "**Step 2: Find distribution of sample mean (XÃÑ)**\n",
    "By CLT:\n",
    "- Mean of sample means = Œº = 20 minutes\n",
    "- Standard error = œÉ/‚àön = 15/‚àö36 = 15/6 = 2.5 minutes\n",
    "- Distribution: XÃÑ ~ Normal(20, 2.5)\n",
    "\n",
    "\n",
    "**Step 3: Calculate probability**\n",
    "P(XÃÑ < 18) = ?\n",
    "\n",
    "Z-score = (18 - 20) / 2.5 = -2 / 2.5 = -0.8\n",
    "\n",
    "Using standard normal table: P(Z < -0.8) ‚âà 0.2119\n",
    "\n",
    "**Answer:** 21.19% chance that average wait time for 36 customers is less than 18 minutes\n",
    "\n",
    "\n",
    "**Key Insight:**\n",
    "- Individual wait times are skewed (not predictable)\n",
    "- But AVERAGE of 36 wait times follows normal distribution (predictable!)\n",
    "- This is the power of CLT\n",
    "\n",
    "\n",
    "## Practical Applications\n",
    "\n",
    "**1. Quality Control:**\n",
    "- Monitor average defect rates across batches\n",
    "- Even if individual items vary wildly, batch averages are predictable\n",
    "\n",
    "**2. A/B Testing:**\n",
    "- Compare average conversion rates between groups\n",
    "- Use normal distribution for hypothesis testing\n",
    "\n",
    "**3. Financial Analysis:**\n",
    "- Average portfolio returns over time periods\n",
    "- Risk assessment using sample means\n",
    "\n",
    "**4. Polling/Surveys:**\n",
    "- Estimate population parameters from sample averages\n",
    "- Create confidence intervals\n",
    "\n",
    "**5. Manufacturing:**\n",
    "- Monitor average product dimensions\n",
    "- Detect when process goes out of control\n",
    "\n",
    "\n",
    "## Visual Example\n",
    "```\n",
    "Population (Skewed):        Sample Means (n=5):      Sample Means (n=30):\n",
    "     *                            **                        ***\n",
    "    ***                          ****                      *****\n",
    "   *****                        ******                    *******\n",
    "  *******___                   ********                  *********\n",
    " *********____              **********___              ***********\n",
    "_______________           ________________          _______________\n",
    "  (Not Normal)            (Getting Normal)           (Very Normal!)\n",
    "```\n",
    "\n",
    "note: CLT is why we can use normal distribution methods in statistics even when dealing with non-normal populations. It's one of the most important theorems in statistics and data science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c6754",
   "metadata": {},
   "source": [
    "## Central Limit Theorem Proof\n",
    "\n",
    "**Theorem Statement:**\n",
    "For a population with mean Œº and standard deviation œÉ, as sample size n increases, the sampling distribution of sample means approaches Normal(Œº, œÉ/‚àön).\n",
    "\n",
    "\n",
    "### Simplified Proof Outline\n",
    "\n",
    "**Step 1: Define Sample Mean**\n",
    "$$\\bar{X} = \\frac{X_1 + X_2 + ... + X_n}{n}$$\n",
    "\n",
    "where X‚ÇÅ, X‚ÇÇ, ..., X‚Çô are independent random samples from population\n",
    "\n",
    "\n",
    "**Step 2: Expected Value of Sample Mean**\n",
    "$$E[\\bar{X}] = E\\left[\\frac{X_1 + X_2 + ... + X_n}{n}\\right] = \\frac{nŒº}{n} = Œº$$\n",
    "\n",
    "The mean of sample means equals population mean\n",
    "\n",
    "\n",
    "**Step 3: Variance of Sample Mean**\n",
    "$$Var(\\bar{X}) = Var\\left(\\frac{X_1 + X_2 + ... + X_n}{n}\\right) = \\frac{nœÉ^2}{n^2} = \\frac{œÉ^2}{n}$$\n",
    "\n",
    "Standard Error: $$SE = \\sqrt{Var(\\bar{X})} = \\frac{œÉ}{\\sqrt{n}}$$\n",
    "\n",
    "\n",
    "**Step 4: Standardization**\n",
    "Standardized sample mean:\n",
    "$$Z = \\frac{\\bar{X} - Œº}{œÉ/\\sqrt{n}}$$\n",
    "\n",
    "\n",
    "**Step 5: Moment Generating Functions (MGF)**\n",
    "Using MGF approach:\n",
    "- As n ‚Üí ‚àû, the MGF of Z converges to MGF of standard normal N(0,1)\n",
    "- By uniqueness theorem, Z ‚Üí N(0,1)\n",
    "- Therefore, XÃÑ ‚Üí N(Œº, œÉ/‚àön)\n",
    "\n",
    "\n",
    "### Key Results\n",
    "\n",
    "1. $$E[\\bar{X}] = Œº$$\n",
    "2. $$SE[\\bar{X}] = \\frac{œÉ}{\\sqrt{n}}$$\n",
    "3. As n ‚Üí ‚àû: $$\\frac{\\bar{X} - Œº}{œÉ/\\sqrt{n}} \\rightarrow N(0,1)$$\n",
    "\n",
    "note: Rigorous proof uses characteristic functions or MGFs and requires advanced probability theory. This is a conceptual outline showing why CLT works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a948a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Credits\n",
    "\n",
    "**Prepared by:**  \n",
    "**Chetan Sharma**  \n",
    "AIML / Data Science Notes  \n",
    "\n",
    "üîó **GitHub:** [github.com/Chetan559](https://github.com/Chetan559)  \n",
    "üåê **Portfolio:** [chetan559.github.io](https://chetan559.github.io)  \n",
    "üíº **LinkedIn:** [linkedin.com/in/sharma-chetan-k](https://www.linkedin.com/in/sharma-chetan-k/)  \n",
    "\n",
    "These notes were compiled for learning, revision, and academic understanding. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
